{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/justheuristic/4c82ef4d448ce62cb5459484f66f56aa/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H91Iz3PiAFEK"
   },
   "source": [
    "### Practice 1: Parallel GloVe\n",
    "\n",
    "In this assignment we'll build parallel GloVe training from scratch. Well, almost from scratch:\n",
    "* we'll use python's builtin [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html) library\n",
    "* and learn to access numpy arrays from multiple processes!\n",
    "\n",
    "![img](https://i.imgur.com/YHluIBo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F9iWJGzIAFEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n",
      "Requirement already satisfied: nltk in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: datasets in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (4.64.0)\n",
      "Requirement already satisfied: joblib in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: aiohttp in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: pandas in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (1.23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: xxhash in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/misha/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/misha/.conda/envs/mlops-new/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "--2022-07-16 05:45:33--  https://raw.githubusercontent.com/mryab/efficient-dl-systems/main/week02_distributed/utils.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1071 (1.0K) [text/plain]\n",
      "Saving to: ‘utils.py’\n",
      "\n",
      "utils.py            100%[===================>]   1.05K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-07-16 05:45:33 (5.60 MB/s) - ‘utils.py’ saved [1071/1071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "# set numpy to single-threaded mode for benchmarking\n",
    "\n",
    "!pip install --upgrade nltk datasets tqdm\n",
    "!wget https://raw.githubusercontent.com/mryab/efficient-dl-systems/main/week02_distributed/utils.py -O utils.py\n",
    "\n",
    "import time, random\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 16 05:45:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.68.02    Driver Version: 510.68.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 26%   33C    P8    13W / 215W |    178MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1407      G   /usr/libexec/Xorg                 167MiB |\n",
      "|    0   N/A  N/A      1489      G   /usr/bin/gnome-shell                9MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:            x86_64\n",
      "  CPU op-mode(s):        32-bit, 64-bit\n",
      "  Address sizes:         39 bits physical, 48 bits virtual\n",
      "  Byte Order:            Little Endian\n",
      "CPU(s):                  8\n",
      "  On-line CPU(s) list:   0-7\n",
      "Vendor ID:               GenuineIntel\n",
      "  Model name:            Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz\n",
      "    CPU family:          6\n",
      "    Model:               158\n",
      "    Thread(s) per core:  1\n",
      "    Core(s) per socket:  8\n",
      "    Socket(s):           1\n",
      "    Stepping:            12\n",
      "    CPU(s) scaling MHz:  72%\n",
      "    CPU max MHz:         4900.0000\n",
      "    CPU min MHz:         800.0000\n",
      "    BogoMIPS:            7200.00\n",
      "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
      "                         a cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss \n",
      "                         ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art\n",
      "                          arch_perfmon pebs bts rep_good nopl xtopology nonstop_\n",
      "                         tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cp\n",
      "                         l vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid ss\n",
      "                         e4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes \n",
      "                         xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_f\n",
      "                         ault epb invpcid_single ssbd ibrs ibpb stibp tpr_shadow\n",
      "                          vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust \n",
      "                         bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap cl\n",
      "                         flushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm\n",
      "                          ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp\n",
      "                          md_clear flush_l1d arch_capabilities\n",
      "Virtualization features: \n",
      "  Virtualization:        VT-x\n",
      "Caches (sum of all):     \n",
      "  L1d:                   256 KiB (8 instances)\n",
      "  L1i:                   256 KiB (8 instances)\n",
      "  L2:                    2 MiB (8 instances)\n",
      "  L3:                    12 MiB (1 instance)\n",
      "NUMA:                    \n",
      "  NUMA node(s):          1\n",
      "  NUMA node0 CPU(s):     0-7\n",
      "Vulnerabilities:         \n",
      "  Itlb multihit:         KVM: Mitigation: VMX disabled\n",
      "  L1tf:                  Not affected\n",
      "  Mds:                   Mitigation; Clear CPU buffers; SMT disabled\n",
      "  Meltdown:              Not affected\n",
      "  Mmio stale data:       Mitigation; Clear CPU buffers; SMT disabled\n",
      "  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl\n",
      "  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer\n",
      "                          sanitization\n",
      "  Spectre v2:            Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIB\n",
      "                         P disabled, RSB filling\n",
      "  Srbds:                 Mitigation; Microcode\n",
      "  Tsx async abort:       Mitigation; TSX disabled\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVojuqhGAFES"
   },
   "source": [
    "### Multiprocessing basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cr6HV2PjAFEU"
   },
   "outputs": [],
   "source": [
    "def foo(i):\n",
    "    \"\"\" Imagine particularly computation-heavy function... \"\"\"\n",
    "    print(end=f\"Began foo({i})...\\n\")\n",
    "    result = np.sin(i)\n",
    "    time.sleep(abs(result))\n",
    "    print(end=f\"Finished foo({i}) = {result:.3f}.\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hOOPAmDdAFEW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Began foo(0)...\n",
      "Finished foo(0) = 0.000.\n",
      "Began foo(1)...\n",
      "Finished foo(1) = 0.841.\n",
      "Began foo(2)...\n",
      "Finished foo(2) = 0.909.\n",
      "Began foo(3)...\n",
      "Finished foo(3) = 0.141.\n",
      "Began foo(4)...\n",
      "Finished foo(4) = -0.757.\n",
      "Began foo(5)...\n",
      "Finished foo(5) = -0.959.\n",
      "Began foo(6)...\n",
      "Finished foo(6) = -0.279.\n",
      "Began foo(7)...\n",
      "Finished foo(7) = 0.657.\n",
      "Began foo(8)...\n",
      "Finished foo(8) = 0.989.\n",
      "Began foo(9)...\n",
      "Finished foo(9) = 0.412.\n",
      "CPU times: user 12.9 ms, sys: 6.19 ms, total: 19.1 ms\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_naive = [foo(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzBc-wA2AFEX"
   },
   "source": [
    "Same, but with multiple processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TQPXLqdlAFEY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 processes!\n",
      "Began foo(0)...\n",
      "Finished foo(0) = 0.000.\n",
      "Began foo(1)...\n",
      "Began foo(2)...\n",
      "Began foo(3)...\n",
      "Began foo(4)...\n",
      "Began foo(5)...\n",
      "Began foo(6)...\n",
      "Began foo(7)...\n",
      "Began foo(8)...\n",
      "Began foo(9)...\n",
      "Finished foo(3) = 0.141.\n",
      "Finished foo(6) = -0.279.\n",
      "Finished foo(9) = 0.412.\n",
      "Finished foo(7) = 0.657.\n",
      "Finished foo(4) = -0.757.\n",
      "Finished foo(1) = 0.841.\n",
      "Finished foo(2) = 0.909.\n",
      "Finished foo(5) = -0.959.\n",
      "Finished foo(8) = 0.989.\n",
      "CPU times: user 20.4 ms, sys: 28.2 ms, total: 48.6 ms\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processes = []\n",
    "for i in range(10):\n",
    "    proc = mp.Process(target=foo, args=[i])\n",
    "    processes.append(proc)\n",
    "\n",
    "print(f\"Created {len(processes)} processes!\")\n",
    "\n",
    "# start in parallel\n",
    "for proc in processes:\n",
    "    proc.start()\n",
    "    \n",
    "# wait for everyone finish\n",
    "for proc in processes:\n",
    "    proc.join()  # wait until proc terminates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-e91ez4AFEZ"
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "Great! But how do we collect the values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJCsKVJsAFEb"
   },
   "source": [
    "__Solution 1:__ with pipes!\n",
    "\n",
    "Two \"sides\", __one__ process from each side\n",
    "* `pipe_side.send(data)` - throw data into the pipe (do not wait for it to be read)\n",
    "* `data = pipe_side.recv()` - read data. If there is none, wait for someone to send data\n",
    "\n",
    "__Rules:__\n",
    "* each side should be controlled by __one__ process\n",
    "* data transferred through pipes must be serializable\n",
    "* if `duplex=True`, processes can communicate both ways\n",
    "* if `duplex=False`, \"left\" receives and \"right\" side sends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lRI8OvzwAFEd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side_B.recv() ->  123\n",
      "side_B.recv() ->  {'ololo': array([-0.46758777,  0.96857925,  0.28746328])}\n"
     ]
    }
   ],
   "source": [
    "side_A, side_B = mp.Pipe()\n",
    "\n",
    "side_A.send(123)\n",
    "side_A.send({'ololo': np.random.randn(3)})\n",
    "\n",
    "print(\"side_B.recv() -> \", side_B.recv())\n",
    "print(\"side_B.recv() -> \", side_B.recv())\n",
    "\n",
    "# note: calling recv a third will hang the process (waiting for someone to send data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KCKp1tq1AFEe"
   },
   "outputs": [],
   "source": [
    "def compute_and_send(i, output_pipe):\n",
    "    print(end=f\"Began compute_and_send({i})...\\n\")\n",
    "    result = np.sin(i)\n",
    "    time.sleep(abs(result))\n",
    "    print(end=f\"Finished compute_and_send({i}) = {result:.3f}.\\n\")\n",
    "    \n",
    "    output_pipe.send(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3j1mKkn5AFEe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Began compute_and_send(0)...\n",
      "Finished compute_and_send(0) = 0.000.\n",
      "Began compute_and_send(1)...\n",
      "Began compute_and_send(2)...\n",
      "Began compute_and_send(3)...\n",
      "Began compute_and_send(4)...\n",
      "Began compute_and_send(5)...\n",
      "Began compute_and_send(6)...\n",
      "Began compute_and_send(7)...\n",
      "Began compute_and_send(8)...\n",
      "Began compute_and_send(9)...\n",
      "Finished compute_and_send(3) = 0.141.\n",
      "MAIN PROCESS: awaiting results...\n",
      "MAIN_PROCESS: received 0.0\n",
      "Finished compute_and_send(6) = -0.279.\n",
      "Finished compute_and_send(9) = 0.412.\n",
      "Finished compute_and_send(7) = 0.657.\n",
      "Finished compute_and_send(4) = -0.757.\n",
      "Finished compute_and_send(1) = 0.841.\n",
      "Finished compute_and_send(2) = 0.909.\n",
      "Finished compute_and_send(5) = -0.959.\n",
      "Finished compute_and_send(8) = 0.989.\n",
      "MAIN_PROCESS: received 0.8414709848078965\n",
      "MAIN_PROCESS: received 0.9092974268256817\n",
      "MAIN_PROCESS: received 0.1411200080598672\n",
      "MAIN_PROCESS: received -0.7568024953079282\n",
      "MAIN_PROCESS: received -0.9589242746631385\n",
      "MAIN_PROCESS: received -0.27941549819892586\n",
      "MAIN_PROCESS: received 0.6569865987187891\n",
      "MAIN_PROCESS: received 0.9893582466233818\n",
      "MAIN_PROCESS: received 0.4121184852417566\n",
      "MAIN PROCESS: done!\n",
      "CPU times: user 28.3 ms, sys: 25 ms, total: 53.3 ms\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_pipes = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    side_A, side_B = mp.Pipe(duplex=False)\n",
    "    # note: duplex=False means that side_B can only send\n",
    "    # and side_A can only recv. Otherwise its bidirectional\n",
    "    result_pipes.append(side_A)\n",
    "    proc = mp.Process(target=compute_and_send, args=[i, side_B])\n",
    "    proc.start()\n",
    "\n",
    "print(\"MAIN PROCESS: awaiting results...\")\n",
    "for pipe in result_pipes:\n",
    "    print(f\"MAIN_PROCESS: received {pipe.recv()}\")\n",
    "print(\"MAIN PROCESS: done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woOzj-h9AFEf"
   },
   "source": [
    "__Solution 2:__ with multiprocessing templates\n",
    "\n",
    "Multiprocessing contains some template data structures that help you communicate between processes.\n",
    "\n",
    "One such structure is `mp.Queue` a Queue that can be accessed by multiple processes in parallel.\n",
    "* `queue.put` adds the value to the queue, accessible by all other processes\n",
    "* `queue.get` returns the earliest added value and removes it from queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P8mPT8uvAFEg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: awaiting queue...\n"
     ]
    }
   ],
   "source": [
    "queue = mp.Queue()\n",
    "\n",
    "def func_A(queue):\n",
    "    print(\"A: awaiting queue...\")\n",
    "    print(\"A: retreived from queue:\", queue.get())\n",
    "    print(\"A: awaiting queue...\")\n",
    "    print(\"A: retreived from queue:\", queue.get())\n",
    "    print(\"A: done!\")\n",
    "\n",
    "def func_B(i, queue):\n",
    "    np.random.seed(i)\n",
    "    value = np.random.rand()\n",
    "    time.sleep(value)\n",
    "    print(f\"proc_B{i}: putting more stuff into queue!\")\n",
    "    queue.put(value)\n",
    "    \n",
    "\n",
    "proc_A = mp.Process(target=func_A, args=[queue])\n",
    "proc_A.start();\n",
    "\n",
    "proc_B1 = mp.Process(target=func_B, args=[1, queue])\n",
    "proc_B2 = mp.Process(target=func_B, args=[2, queue])\n",
    "proc_B1.start(), proc_B2.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-rzgIRPAFEh"
   },
   "source": [
    "__Important note:__ you can see that the two values above are identical.\n",
    "\n",
    "This is because proc_B1 and proc_B2 were forked (cloned) with __the same random state!__\n",
    "\n",
    "To mitigate this issue, run `np.random.seed()` in each process (same for torch, tensorflow).\n",
    "\n",
    "<details>\n",
    "    <summary>In fact, please go and to that <b>right now!</b></summary>\n",
    "    <img src='https://media.tenor.com/images/32c950f36a61ec7e5060f5eee9140396/tenor.gif' height=200px>\n",
    "</details>\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "__Less important note:__ `mp.Queue vs mp.Pipe`\n",
    "- pipes are much faster for 1v1 communication\n",
    "- queues support arbitrary number of processes\n",
    "- queues are implemented with pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHck3-qUAFEi"
   },
   "source": [
    "### GloVe preprocessing\n",
    "\n",
    "Before we can train GloVe, we must first construct the co-occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qNC7L4avAFEj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2578a3f916974c8abf9f29575097089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61efef2a79ff416c91dd5026ef6f0667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-103-raw-v1 (download: 183.09 MiB, generated: 523.53 MiB, post-processed: Unknown size, total: 706.63 MiB) to /home/misha/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176aeacf0ed9471b9da26c555e2dbd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0b0b8494e04565b96e292dc0af71a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfe8ed56cd04665ab49e1ac746966ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a29dcd790584a19a5216de68912b1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to /home/misha/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e3b00364284339b4746ae0ceb01a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:  It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "data = datasets.load_dataset('wikitext', 'wikitext-103-raw-v1')\n",
    "# for fast debugging, you can temporarily use smaller data: 'wikitext-2-raw-v1'\n",
    "\n",
    "print(\"Example:\", data['train']['text'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctIVLlsaAFEk"
   },
   "source": [
    "__First,__ let's build a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-3LTURX-AFEl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 459,\n",
       "         ',': 349,\n",
       "         '.': 225,\n",
       "         'of': 193,\n",
       "         'to': 150,\n",
       "         'and': 147,\n",
       "         'in': 104,\n",
       "         '@': 100,\n",
       "         'a': 93,\n",
       "         'was': 83})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import NLTKWordTokenizer\n",
    "tokenizer = NLTKWordTokenizer()\n",
    "\n",
    "def count_tokens(lines, top_k=None):\n",
    "    \"\"\" Tokenize lines and return top_k most frequent tokens and their counts \"\"\"\n",
    "    sent_tokens = tokenizer.tokenize_sents(map(str.lower, lines))\n",
    "    token_counts = Counter([token for sent in sent_tokens for token in sent])\n",
    "    return Counter(dict(token_counts.most_common(top_k)))\n",
    "\n",
    "count_tokens(data['train']['text'][:100], top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YCyX3nruAFEm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.942974723002408 sec..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sequential algorithm\n",
    "from timeit import default_timer\n",
    "\n",
    "texts = data['train']['text'][:100_000]\n",
    "vocabulary_size = 32_000\n",
    "batch_size = 10_000\n",
    "\n",
    "token_counts = Counter()\n",
    "start = default_timer()\n",
    "for batch_start in trange(0, len(texts), batch_size):\n",
    "    batch_texts = texts[batch_start: batch_start + batch_size]\n",
    "    batch_counts = count_tokens(batch_texts, top_k=vocabulary_size)\n",
    "    token_counts += Counter(batch_counts)\n",
    "\n",
    "# save for later\n",
    "token_counts_reference = Counter(token_counts)\n",
    "\n",
    "end = default_timer()\n",
    "print(f'Took {end - start} sec..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nsYnwdFAFEo"
   },
   "source": [
    "### Let's parallelize (20% points)\n",
    "\n",
    "__Your task__ is to speed up the code above using using multiprocessing with queues and/or pipes _(or [shared memory](https://docs.python.org/3/library/multiprocessing.shared_memory.html) if you're up to that)_.\n",
    "\n",
    "__Kudos__ for implementing some form of global progress tracker (like progressbar above)\n",
    "\n",
    "Please do **not** use task executors (e.g. mp.pool, joblib, ProcessPoolExecutor), we'll get to them soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "k4IporOCAFEo"
   },
   "outputs": [],
   "source": [
    "texts = data['train']['text'][:100_000]\n",
    "vocabulary_size = 32_000\n",
    "batch_size = 10_000\n",
    "\n",
    "def count_step(texts, slice_index, batch_size, output_pipe):\n",
    "    token_counts = Counter()\n",
    "\n",
    "    for batch_start in trange(slice_index[0], slice_index[1], batch_size):\n",
    "        batch_end = min(batch_start + batch_size, slice_index[1])\n",
    "        batch_texts = texts[batch_start: batch_end]\n",
    "        batch_counts = count_tokens(batch_texts, top_k=vocabulary_size)\n",
    "        token_counts += Counter(batch_counts)\n",
    "\n",
    "    output_pipe.send(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def straight_slice_indexes(slices_indexes, batch_size):\n",
    "    last_ix = slices_indexes[-1][-1]\n",
    "    for i in range(len(slices_indexes)):\n",
    "        for j in range(len(slices_indexes[i])):            \n",
    "            if slices_indexes[i][j] % batch_size != 0:\n",
    "                slices_indexes[i][j] = ((slices_indexes[i][j] // batch_size) + 1) * batch_size\n",
    "                \n",
    "    slices_indexes[-1][-1] = min(slices_indexes[-1][-1], last_ix)\n",
    "    return slices_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 30], [30, 50], [50, 80], [80, 100]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "straight_slice_indexes([[0, 25], [25, 50], [50, 75], [75, 100]], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_token_counts_parallel(texts, vocabulary_size, batch_size):\n",
    "    n_cpu = n_slices = mp.cpu_count()\n",
    "    slice_size = len(texts) // n_slices\n",
    "    slices_indexes = [[i * slice_size,(i + 1) * slice_size] for i in range(n_cpu)]\n",
    "    print('Prepared indexes:', slices_indexes)\n",
    "    slices_indexes = straight_slice_indexes(slices_indexes, batch_size)\n",
    "    print('Aligned indexes:', slices_indexes)\n",
    "\n",
    "    result_pipes = []\n",
    "    start = default_timer()\n",
    "    \n",
    "    for i in range(n_cpu):\n",
    "        side_A, side_B = mp.Pipe(duplex=False)\n",
    "        result_pipes.append(side_A)\n",
    "        proc_i = mp.Process(target=count_step, args=[texts, slices_indexes[i], batch_size, side_B])\n",
    "        proc_i.start()\n",
    "        # processes.append(proc_i)\n",
    "\n",
    "    result = Counter()\n",
    "    print(\"Awaiting pipe_results...\")\n",
    "\n",
    "    for pipe in result_pipes:\n",
    "        r = pipe.recv()\n",
    "        result += r\n",
    "    print(\"Finished waiting!\")\n",
    "\n",
    "    end = default_timer()\n",
    "    print(f'Took {end - start} sec..')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared indexes: [[0, 12500], [12500, 25000], [25000, 37500], [37500, 50000], [50000, 62500], [62500, 75000], [75000, 87500], [87500, 100000]]\n",
      "Aligned indexes: [[0, 20000], [20000, 30000], [30000, 40000], [40000, 50000], [50000, 70000], [70000, 80000], [80000, 90000], [90000, 100000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awaiting pipe_results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished waiting!\n",
      "Took 2.9382015580195002 sec..\n"
     ]
    }
   ],
   "source": [
    "texts = data['train']['text'][:100_000]\n",
    "vocabulary_size = 32_000\n",
    "batch_size = 10_000\n",
    "\n",
    "\n",
    "token_counts = compute_token_counts_parallel(texts, vocabulary_size, batch_size)\n",
    "token_counts = Counter(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ygCy9JSKAFEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "assert len(token_counts) == len(token_counts_reference)\n",
    "for token, ref_count in token_counts_reference.items():\n",
    "    assert token in token_counts, token\n",
    "    assert token_counts[token] == ref_count, token\n",
    "\n",
    "token_counts = Counter(dict(token_counts.most_common(vocabulary_size)))\n",
    "\n",
    "vocabulary = sorted(token_counts.keys())\n",
    "token_to_index = {token: i for i, token in enumerate(vocabulary)}\n",
    "assert len(vocabulary) == vocabulary_size, len(vocabulary)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgALuOgdAFEp"
   },
   "source": [
    "### Part 2: Construct co-occurence matrix (10% points)\n",
    "\n",
    "\n",
    "__Your task__ is to count co-occurences of all words in a 5-token window. Please use the same preprocessing and tokenizer as above.\n",
    "\n",
    "__Also:__ please only count words that are in the vocabulary defined above.\n",
    "\n",
    "![image.png](https://i.imgur.com/2XmhYn5.png)\n",
    "\n",
    "\n",
    "\n",
    "__Note:__ this task and everything below has no instructions/interfaces. We will design those interfaces __together on the seminar.__\n",
    "\n",
    "The detailed instructions will appear later this night after the seminar is over.\n",
    "However, if you want to write the code from scratch, feel free to ignore these instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1N1acrkUAFEq"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def count_token_cooccurences(lines, vocabulary_size: int, window_size: int):\n",
    "    \"\"\" Tokenize lines and return top_k most frequent tokens and their counts \"\"\"\n",
    "    cooc = Counter()\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = tokenizer.tokenize(line.lower())\n",
    "        token_ix = [token_to_index[token] for token in tokens\n",
    "                    if token in token_to_index]\n",
    "        \n",
    "        for i in range(len(token_ix)):\n",
    "            for j in range(max(i - window_size, 0),\n",
    "                           min(i + window_size + 1, len(token_ix))):\n",
    "                if i != j:\n",
    "                    cooc[token_ix[i], token_ix[j]] += 1 / abs(i - j)\n",
    "    return counter_to_matrix(cooc, vocabulary_size)\n",
    "\n",
    "def counter_to_matrix(counter, vocabulary_size):\n",
    "    keys, values = zip(*counter.items())\n",
    "    ii, jj = zip(*keys)\n",
    "    return scipy.sparse.csr_matrix((values, (ii, jj)), dtype='float32',\n",
    "                                   shape=(vocabulary_size, vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "QpvoJI4TAFEq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:01<00:00,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 63.04234870499931 sec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "texts = data['train']['text'][:100_000]\n",
    "batch_size = 10_000\n",
    "window_size = 5\n",
    "\n",
    "cooc = scipy.sparse.csr_matrix((vocabulary_size, vocabulary_size), dtype='float32')\n",
    "for batch_start in trange(0, len(texts), batch_size):\n",
    "    batch_texts = texts[batch_start: batch_start + batch_size]\n",
    "    batch_cooc = count_token_cooccurences(batch_texts, vocabulary_size, window_size)\n",
    "    cooc += batch_cooc\n",
    "    \n",
    "\n",
    "# This cell will run for a couple minutes, go get some tea!\n",
    "reference_cooc = cooc\n",
    "\n",
    "end = default_timer()\n",
    "print(f'Took {end - start} sec...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-iwaVloAFEr"
   },
   "source": [
    "__Simple parallelism with `mp.Pool`__\n",
    "\n",
    "Many standard parallel tasks, such as applying the same function to an array of inputs, can be automated by using prebuilt primitives such as Pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_cooc(texts, slice_index, batch_size, vocabulary_size, cooc):\n",
    "    texts = texts[slice_index[0]:slice_index[1]]\n",
    "    for batch_start in trange(0, len(texts), batch_size):\n",
    "        batch_texts = texts[batch_start: batch_start + batch_size]\n",
    "        batch_cooc = count_token_cooccurences(batch_texts, vocabulary_size, window_size)\n",
    "        cooc += batch_cooc\n",
    "    return cooc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-45tfQN7AFEs"
   },
   "source": [
    "__Our next step__ is to implement a parallel version of co-occurence computation using the process pool functionality.\n",
    "\n",
    "There are multiple alternatives to mp.Pool: [joblib.Parallel](https://joblib.readthedocs.io/en/latest/), [ProcessPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor), [ipyparallel](https://github.com/ipython/ipyparallel), etc. Feel free to use whichever one you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mSp_OQzxAFEs",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.42s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.70s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.67s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.76s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.98s/it]\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.19s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.96s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16.58051970001543 sec...\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "start = default_timer()\n",
    "\n",
    "texts = data['train']['text'][:100_000]\n",
    "batch_size = 10_000\n",
    "window_size = 5\n",
    "n_cpu = n_slices = mp.cpu_count()\n",
    "slice_size = len(texts) // n_slices\n",
    "slices_indexes = [(i * slice_size,(i + 1) * slice_size) for i in range(n_cpu)]\n",
    "cooc = scipy.sparse.csr_matrix((vocabulary_size, vocabulary_size), dtype='float32')\n",
    "\n",
    "params = []\n",
    "for slice_index in slices_indexes:\n",
    "    param = (texts, slice_index, batch_size, vocabulary_size, cooc)\n",
    "    params.append(param)\n",
    "\n",
    "with mp.Pool(processes=n_cpu) as pool:\n",
    "    ll = pool.starmap(get_ref_cooc, params)\n",
    "    \n",
    "cooc = reduce(add, ll)\n",
    "end = default_timer()\n",
    "print(f'Took {end - start} sec...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:07<00:00, 14148.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(cooc, scipy.sparse.csr_matrix)\n",
    "assert cooc.nnz == reference_cooc.nnz\n",
    "for _ in trange(100_000):\n",
    "    i, j = np.random.randint(0, vocabulary_size, size=2)\n",
    "    assert np.allclose(cooc[i, j], reference_cooc[i, j])\n",
    "\n",
    "print(\"Perfect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zanNUlMpAFEt"
   },
   "source": [
    "__Preprocess and save the full data__\n",
    "\n",
    "Finally, let's run the preprocessing code for the entire dataset and save the results for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MQLkgNtUAFEt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared indexes: [[0, 225168], [225168, 450336], [450336, 675504], [675504, 900672], [900672, 1125840], [1125840, 1351008], [1351008, 1576176], [1576176, 1801344]]\n",
      "Aligned indexes: [[0, 230000], [230000, 460000], [460000, 680000], [680000, 910000], [910000, 1130000], [1130000, 1360000], [1360000, 1580000], [1580000, 1801344]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awaiting pipe_results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:31<00:00,  1.41s/it]\n",
      "100%|██████████| 22/22 [00:31<00:00,  1.43s/it]\n",
      "100%|██████████| 23/23 [00:31<00:00,  1.38s/it]\n",
      "100%|██████████| 22/22 [00:31<00:00,  1.45s/it]\n",
      "100%|██████████| 23/23 [00:32<00:00,  1.41s/it]\n",
      "100%|██████████| 23/23 [00:32<00:00,  1.41s/it]\n",
      "100%|██████████| 23/23 [00:32<00:00,  1.43s/it]\n",
      "100%|██████████| 23/23 [00:32<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished waiting!\n",
      "Took 33.52596546703717 sec..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [04:18<00:00, 11.22s/it]\n",
      "100%|██████████| 23/23 [04:16<00:00, 11.16s/it]\n",
      "100%|██████████| 23/23 [04:22<00:00, 11.41s/it]\n",
      "100%|██████████| 23/23 [04:21<00:00, 11.38s/it]\n",
      "100%|██████████| 23/23 [04:19<00:00, 11.30s/it]\n",
      "100%|██████████| 23/23 [04:18<00:00, 11.23s/it]\n",
      "100%|██████████| 23/23 [04:20<00:00, 11.33s/it]\n",
      "100%|██████████| 23/23 [04:26<00:00, 11.57s/it]\n"
     ]
    }
   ],
   "source": [
    "texts = data['train']['text']\n",
    "vocabulary_size = 32_000\n",
    "batch_size = 10_000\n",
    "window_size = 5\n",
    "\n",
    "# YOUR CODE: compute both vocabulary and cooc on the entire training corpora and save the results\n",
    "\n",
    "token_counts = compute_token_counts_parallel(texts, vocabulary_size, batch_size)\n",
    "token_counts = Counter(token_counts)\n",
    "\n",
    "n_cpu = n_slices = mp.cpu_count()\n",
    "slice_size = len(texts) // n_slices\n",
    "slices_indexes = [(i * slice_size,(i + 1) * slice_size) for i in range(n_cpu)]\n",
    "cooc = scipy.sparse.csr_matrix((vocabulary_size, vocabulary_size), dtype='float32')\n",
    "\n",
    "params = []\n",
    "for slice_index in slices_indexes:\n",
    "    param = (texts, slice_index, batch_size, vocabulary_size, cooc)\n",
    "    params.append(param)\n",
    "\n",
    "with mp.Pool(processes=n_cpu) as pool:\n",
    "    ll = pool.starmap(get_ref_cooc, params)\n",
    "    \n",
    "cooc = reduce(add, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CdxoorbBAFEu"
   },
   "outputs": [],
   "source": [
    "assert len(vocabulary) == vocabulary_size\n",
    "assert cooc.shape == (vocabulary_size, vocabulary_size)\n",
    "assert 440_000_000 < np.sum(cooc) < 450_000_000\n",
    "assert 0.05 < cooc.nnz / vocabulary_size ** 2 < 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GZXhjIFJAFEu"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preprocessed_data.pcl', 'wb') as f:\n",
    "    pickle.dump((vocabulary, cooc.tocoo()), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rN314cCAFEu"
   },
   "source": [
    "### Finally, GloVe!  (20% points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vNLaUatnAFEu"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preprocessed_data.pcl', 'rb') as f:\n",
    "    vocabulary, cooc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e401y6JAFEu"
   },
   "source": [
    "### Weight function\n",
    "![image.png](https://i.imgur.com/Cdu6BJ5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-O7lIzauAFEw"
   },
   "outputs": [],
   "source": [
    "def compute_loss_weights(counts_ij):\n",
    "    \"\"\" Compute GloVe weights \"\"\"\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "    return [(x / x_max)**alpha if x < x_max else 1 for x in counts_ij]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OTya47l8AFEw"
   },
   "outputs": [],
   "source": [
    "dummy_weights = compute_loss_weights(np.arange(0, 200, 30))\n",
    "dummy_reference_weights = [0. , 0.40536, 0.681731, 0.92402, 1. , 1. , 1.]\n",
    "assert np.allclose(dummy_weights, dummy_reference_weights, rtol=1e-4, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4a6DJqjAFEw"
   },
   "source": [
    "### Loss function\n",
    "\n",
    "![img](https://i.imgur.com/bkEBBLk.png)\n",
    "\n",
    "\n",
    "__The goal__ is to compute the loss function as per formula above. The only difference is that you should take _mean_ over batch instead of sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bempH2-4AFEw"
   },
   "outputs": [],
   "source": [
    "def compute_loss(emb_ii, emb_jj, bias_ii, bias_jj, counts_ij):\n",
    "    \"\"\"\n",
    "    Compute GloVe loss function given embeddings, biases and targets\n",
    "    \n",
    "    :param emb_ii, emb_jj: vectors of left- and right-side words, shape: [batch_size, embedding_dimension]\n",
    "    :param bias_ii, bias_jj: biases for left- and right-side words, shape: [batch_size]\n",
    "    :param counts_ij: values from co-occurence matrix, shape: [batch_size]\n",
    "    :returns: mean GloVe loss over batch, shape: scalar\n",
    "    \"\"\"\n",
    "    weights = compute_loss_weights(counts_ij)\n",
    "    target = np.log(counts_ij)\n",
    "    loss = weights * (np.sum(emb_ii * emb_jj, axis=1) + bias_ii + bias_jj - target)**2\n",
    "    return np.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "IFO8TyMkAFEx"
   },
   "outputs": [],
   "source": [
    "dummy_emb_ii = np.sin(np.linspace(0, 10, 40)).reshape(4, 10)\n",
    "dummy_emb_jj = np.cos(np.linspace(10, 20, 40)).reshape(4, 10)\n",
    "dummy_bias_ii = np.linspace(-3, 2, 4)\n",
    "dummy_bias_jj = np.linspace(4, -1, 4)\n",
    "dummy_counts_ij = np.abs(np.sin(np.linspace(1, 100, 4)) * 150)\n",
    "\n",
    "dummy_loss = compute_loss(dummy_emb_ii, dummy_emb_jj, dummy_bias_ii, dummy_bias_jj, dummy_counts_ij)\n",
    "assert np.shape(dummy_loss) == ()\n",
    "assert np.allclose(dummy_loss, 1.84289356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "c81syAvPAFEx"
   },
   "outputs": [],
   "source": [
    "def compute_grads(emb_ii, emb_jj, bias_ii, bias_jj, counts_ij):\n",
    "    \"\"\"\n",
    "    Compute gradients of GloVe loss with respect to emb_ii/jj and bias_ii/jj\n",
    "    Assume the same parameter shapes as above\n",
    "    :returns: (grad_wrt_emb_ii, grad_wrt_emb_jj, grad_wrt_bias_ii, grad_wrt_bias_jj)\n",
    "    \"\"\"\n",
    "    weights = np.array(compute_loss_weights(counts_ij))\n",
    "    target = np.log(counts_ij)\n",
    "    common = weights * (np.sum(emb_ii * emb_jj, axis=1) + bias_ii + bias_jj - target) * 2 \n",
    "    grad_wrt_bias_ii = grad_wrt_bias_jj = common\n",
    "        \n",
    "    grad_wrt_emb_jj = common.reshape(-1, 1) * emb_ii\n",
    "    grad_wrt_emb_ii = common.reshape(-1, 1) * emb_jj\n",
    "    \n",
    "    # correction by division N:\n",
    "    ls = [grad_wrt_emb_ii, grad_wrt_emb_jj, grad_wrt_bias_ii, grad_wrt_bias_jj]\n",
    "    for i in range(len(ls)):\n",
    "        ls[i] = ls[i] / ls[i].shape[0]\n",
    "    \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "WMKNKChwAFEx"
   },
   "outputs": [],
   "source": [
    "grad_emb_ii, grad_emb_jj, grad_bias_ii, grad_bias_jj = compute_grads(\n",
    "    dummy_emb_ii, dummy_emb_jj, dummy_bias_ii, dummy_bias_jj, dummy_counts_ij)\n",
    "\n",
    "assert np.shape(grad_emb_ii) == np.shape(grad_emb_jj) == np.shape(dummy_emb_ii)\n",
    "assert np.shape(grad_bias_ii) == np.shape(grad_bias_jj) == np.shape(dummy_bias_ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "LBrXg99RAFEy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/db[ii] OK\n",
      "dL/db[jj] OK\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_numerical_gradient\n",
    "reference_grad_bias_ii = eval_numerical_gradient(\n",
    "    lambda x: compute_loss(dummy_emb_ii, dummy_emb_jj, x, dummy_bias_jj, dummy_counts_ij),\n",
    "    x=dummy_bias_ii)\n",
    "\n",
    "assert np.allclose(reference_grad_bias_ii, grad_bias_ii, rtol=1e-4, atol=1e-3)\n",
    "print(\"dL/db[ii] OK\")\n",
    "\n",
    "reference_grad_bias_jj = eval_numerical_gradient(\n",
    "    lambda x: compute_loss(dummy_emb_ii, dummy_emb_jj, dummy_bias_ii, x, dummy_counts_ij),\n",
    "    x=dummy_bias_jj)\n",
    "\n",
    "assert np.allclose(reference_grad_bias_jj, grad_bias_jj, rtol=1e-4, atol=1e-3)\n",
    "print(\"dL/db[jj] OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.69662399, -0.72184175, -0.85898326, -0.00747297]),\n",
       " array([-0.69662399, -0.72184175, -0.85898326, -0.00747297]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_grad_bias_jj, grad_bias_jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "v8Unp2sHAFEy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dEmb[ii] OK\n",
      "dL/dEmb[ii] OK\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "reference_grad_emb_ii = eval_numerical_gradient(\n",
    "    lambda x: compute_loss(x, dummy_emb_jj, dummy_bias_ii, dummy_bias_jj, dummy_counts_ij),\n",
    "    x=dummy_emb_ii)\n",
    "\n",
    "assert np.allclose(reference_grad_emb_ii, grad_emb_ii, rtol=1e-4, atol=1e-3)\n",
    "print(\"dL/dEmb[ii] OK\")\n",
    "\n",
    "\n",
    "reference_grad_emb_jj = eval_numerical_gradient(\n",
    "    lambda x: compute_loss(dummy_emb_ii, x, dummy_bias_ii, dummy_bias_jj, dummy_counts_ij),\n",
    "    x=dummy_emb_jj)\n",
    "\n",
    "assert np.allclose(reference_grad_emb_jj, grad_emb_jj, rtol=1e-4, atol=1e-3)\n",
    "print(\"dL/dEmb[ii] OK\")\n",
    "\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiRd2ERLAFEz"
   },
   "source": [
    "### Part 3: Parallel GloVe training (50% points)\n",
    "\n",
    "Finally, let's write the actual parameter server for parallel GloVe training. In order to do so efficiently, we shall use shared memory instead of pipes.\n",
    "\n",
    "You can find an example of how shared memory works below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8AF358WAFE0"
   },
   "source": [
    "### Demo: shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-X0UxoWpAFE0"
   },
   "outputs": [],
   "source": [
    "def make_shared_array(shape, dtype, fill=None, lock=True):\n",
    "    \"\"\" Create a numpy array that is shared across processes. \"\"\"\n",
    "    size = int(np.prod(shape))\n",
    "    ctype = np.ctypeslib.as_ctypes_type(dtype)\n",
    "    if lock:\n",
    "        x_mp = mp.Array(ctype, size, lock=True).get_obj()\n",
    "    else:\n",
    "        x_mp = mp.Array(ctype, size, lock=False)\n",
    "    array = np.ctypeslib.as_array(x_mp)\n",
    "    if fill is not None:\n",
    "        array[...] = fill\n",
    "    return np.reshape(array, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9Lc775zDAFE1"
   },
   "outputs": [],
   "source": [
    "shared_array = make_shared_array((5, 5), 'float32', fill=1)\n",
    "normal_array = np.ones((5, 5), 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "yXishO2FAFE2"
   },
   "outputs": [],
   "source": [
    "def proc_A():\n",
    "    time.sleep(0.5)\n",
    "    print(\"A: setting value at [2, 3]\")\n",
    "    shared_array[2, 3] = 42\n",
    "    normal_array[2, 3] = 42\n",
    "    time.sleep(1)\n",
    "    print(f\"A: value after 1.5s: normal = {normal_array[2, 3]}\\t shared = {shared_array[2, 3]}\")\n",
    "    \n",
    "def proc_B():\n",
    "    print(f\"B: initial value: normal = {normal_array[2, 3]}\\t shared = {shared_array[2, 3]}\")\n",
    "    time.sleep(1)\n",
    "    print(f\"B: value after 1s: normal = {normal_array[2, 3]}\\t shared = {shared_array[2, 3]}\")\n",
    "    print(\"B: dividing value at [2, 3] by 2\")\n",
    "    shared_array[2, 3] /= 2\n",
    "    normal_array[2, 3] /= 2\n",
    "    time.sleep(1)\n",
    "    print(f\"B: value after 2s: normal = {normal_array[2, 3]}\\t shared = {shared_array[2, 3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "81N-7Xi9AFE3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: initial value: normal = 1.0\t shared = 1.0"
     ]
    }
   ],
   "source": [
    "mp.Process(target=proc_A).start()\n",
    "mp.Process(target=proc_B).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BWm-b7dRAFE4"
   },
   "outputs": [],
   "source": [
    "# the same can be done with individual values:\n",
    "x = mp.Value(np.ctypeslib.as_ctypes_type(np.int32))\n",
    "x.value += 1 # shared across all processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG-du4ddAFE6"
   },
   "source": [
    "__So, let's put all trainable parameters in shared memory!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "c1JB__1kAFE6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SharedEmbeddings:\n",
    "    \"\"\"\n",
    "    Word embeddings trainable parameters, allocated in shared memory\n",
    "    \"\"\"\n",
    "    def __init__(self, vocabulary_size: int, embedding_dimension: int, init_scale: float = 0.01):\n",
    "        self.embeddings = make_shared_array([vocabulary_size, embedding_dimension], np.float32, lock=False)\n",
    "        self.embeddings[...] = np.random.randn(*self.embeddings.shape) * init_scale\n",
    "        \n",
    "        self.biases = make_shared_array([vocabulary_size], np.float32, fill=0.0, lock=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr5PV0MfAFE6"
   },
   "source": [
    "### Training (single-core baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "max_steps = 10 ** 6\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "timestep_history = []\n",
    "loss_history = []\n",
    "\n",
    "model = SharedEmbeddings(vocabulary_size, embedding_dimension=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "kYwgvX5CAFE7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [05:39<00:00, 2944.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-core. Took 339.61716469796374 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "for t in trange(max_steps):\n",
    "    batch_ix = np.random.randint(0, len(cooc.row), size=batch_size)\n",
    "    ii, jj, counts_ij = cooc.row[batch_ix], cooc.col[batch_ix], cooc.data[batch_ix]\n",
    "    \n",
    "    # Compute gradients\n",
    "    emb_ii, emb_jj, bias_ii, bias_jj = \\\n",
    "      model.embeddings[ii], model.embeddings[jj], model.biases[ii], model.biases[jj]\n",
    "    \n",
    "    grad_emb_ii, grad_emb_jj, grad_bias_ii, grad_bias_jj = compute_grads(\n",
    "        emb_ii, emb_jj, bias_ii, bias_jj, counts_ij)\n",
    "    \n",
    "    # SGD step\n",
    "    model.embeddings[ii] -= learning_rate * grad_emb_ii\n",
    "    model.embeddings[jj] -= learning_rate * grad_emb_jj\n",
    "    model.biases[ii] -= learning_rate * grad_bias_ii\n",
    "    model.biases[jj] -= learning_rate * grad_bias_jj\n",
    "    \n",
    "    if t % 10_000 == 0:\n",
    "        batch_ix = np.random.randint(0, len(cooc.row), size=4096)\n",
    "        ii, jj, counts_ij = cooc.row[batch_ix], cooc.col[batch_ix], cooc.data[batch_ix]\n",
    "        emb_ii, emb_jj, bias_ii, bias_jj = \\\n",
    "            model.embeddings[ii], model.embeddings[jj], model.biases[ii], model.biases[jj]\n",
    "        \n",
    "        loss = compute_loss(emb_ii, emb_jj, bias_ii, bias_jj, counts_ij)\n",
    "        print(f'Iter :{t},\\t, process: {os.getpid()} Loss: {loss}')\n",
    "\n",
    "\n",
    "        timestep_history.append(time.perf_counter() - start_time)\n",
    "        loss_history.append(compute_loss(emb_ii, emb_jj, bias_ii, bias_jj, counts_ij))\n",
    "        clear_output(True)\n",
    "        plt.plot(timestep_history, loss_history)\n",
    "        plt.xlabel('training time(seconds)')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "end = default_timer()\n",
    "print(f'Single-core. Took {end - start} seconds...')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noZiGvffAFE8"
   },
   "source": [
    "__Now let's parallelize it!__\n",
    "\n",
    "The code above is cute, but it only uses one CPU core. Surely we can go faster!\n",
    "\n",
    "The main challenge in this week's seminar is to speed up GloVe training by all means necessary.\n",
    "\n",
    "Here's what you should do:\n",
    "* make multiple parallel workers, each training your model on different random data,\n",
    "* build some centralized means of progress tracking: track the average loss and the number of training steps,\n",
    "* implement workers in such a way that no process is left hanging after the training is over.\n",
    "\n",
    "\n",
    "Finally, please compare the loss / training time plot of your algorithm against the baseline.\n",
    "\n",
    "_Notes:_\n",
    "* Remember to set a different np.random.seed in each worker!\n",
    "* You can track the training progress either via mp.Pipe or via shared variables\n",
    "* It is better to separate training and plotting into different processes\n",
    "* If you want to prevent concurrent updates to shared memory, you can use [mp.Lock](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Lock) or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "uTD4WQtjAFE9"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "max_steps = 10 ** 6\n",
    "start_time = time.perf_counter()\n",
    "timestep_history = []\n",
    "loss_history = []\n",
    "\n",
    "model = SharedEmbeddings(vocabulary_size, embedding_dimension=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(batch_ix, t, output_queue):\n",
    "    ii, jj, counts_ij = cooc.row[batch_ix], cooc.col[batch_ix], cooc.data[batch_ix]\n",
    "    \n",
    "    # Compute gradients\n",
    "    emb_ii, emb_jj, bias_ii, bias_jj = \\\n",
    "      model.embeddings[ii], model.embeddings[jj], model.biases[ii], model.biases[jj]\n",
    "    \n",
    "    grad_emb_ii, grad_emb_jj, grad_bias_ii, grad_bias_jj = compute_grads(\n",
    "        emb_ii, emb_jj, bias_ii, bias_jj, counts_ij)\n",
    "    \n",
    "    # SGD step\n",
    "    model.embeddings[ii] -= learning_rate * grad_emb_ii\n",
    "    model.embeddings[jj] -= learning_rate * grad_emb_jj\n",
    "    model.biases[ii] -= learning_rate * grad_bias_ii\n",
    "    model.biases[jj] -= learning_rate * grad_bias_jj\n",
    "    if t % 10_000 == 0:\n",
    "        batch_ix = np.random.randint(0, len(cooc.row), size=4096)\n",
    "        ii, jj, counts_ij = cooc.row[batch_ix], cooc.col[batch_ix], cooc.data[batch_ix]\n",
    "        emb_ii, emb_jj, bias_ii, bias_jj = \\\n",
    "            model.embeddings[ii], model.embeddings[jj], model.biases[ii], model.biases[jj]\n",
    "        loss = compute_loss(emb_ii, emb_jj, bias_ii, bias_jj, counts_ij)\n",
    "        print(f'Iter :{t},\\t, process: {os.getpid()} Loss: {loss}')\n",
    "\n",
    "        # lock.acquire()\n",
    "        # timestep_history.append()\n",
    "        time_stamp = time.perf_counter() - start_time\n",
    "        output_queue.put((time_stamp, loss))\n",
    "        # lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(stack, output_queue):\n",
    "    while stack:\n",
    "        t, batch_ix = stack.get()\n",
    "        if t=='kill':\n",
    "            print(f'Process {os.getpid()} is killed\\n')\n",
    "            return\n",
    "        update_step(batch_ix, t, output_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ix = zip(list(range(max_steps)), np.random.randint(0, len(cooc.row), size=(max_steps, batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "n_cpu = mp.cpu_count()\n",
    "stack = deque(batch_ix)\n",
    "stack.extend([('kill','kill')]*n_cpu)\n",
    "lock = mp.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue.close()\n",
    "# queue.join_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = mp.Queue()\n",
    "for el in stack:\n",
    "    queue.put(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_queue = mp.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter :0,\t, process: 20170 Loss: 0.4897383476470163\n",
      "Iter :10000,\t, process: 20177 Loss: 0.44107612357993414\n",
      "Iter :20000,\t, process: 20177 Loss: 0.3341316399121065\n",
      "Iter :30000,\t, process: 20178 Loss: 0.3718737725252671\n",
      "Iter :40000,\t, process: 20182 Loss: 0.34720468866500687\n",
      "Iter :50000,\t, process: 20170 Loss: 0.2673943025646888\n",
      "Iter :60000,\t, process: 20181 Loss: 0.31005308206017135\n",
      "Iter :70000,\t, process: 20178 Loss: 0.23858914947009055\n",
      "Iter :80000,\t, process: 20179 Loss: 0.28321213141394197\n",
      "Iter :90000,\t, process: 20178 Loss: 0.27910172897204244\n",
      "Iter :100000,\t, process: 20178 Loss: 0.232736121516992\n",
      "Iter :110000,\t, process: 20178 Loss: 0.2529086154137387\n",
      "Iter :120000,\t, process: 20182 Loss: 0.1946053204437262\n",
      "Iter :130000,\t, process: 20177 Loss: 0.23963522709567636\n",
      "Iter :140000,\t, process: 20182 Loss: 0.23240936789969563\n",
      "Iter :150000,\t, process: 20182 Loss: 0.20196450880367062\n",
      "Iter :160000,\t, process: 20181 Loss: 0.17423517121851503\n",
      "Iter :170000,\t, process: 20170 Loss: 0.21464788832114406\n",
      "Iter :180000,\t, process: 20182 Loss: 0.2027063531272654\n",
      "Iter :190000,\t, process: 20180 Loss: 0.21571276030450137\n",
      "Iter :200000,\t, process: 20170 Loss: 0.1824259582725223\n",
      "Iter :210000,\t, process: 20181 Loss: 0.19764771619610177\n",
      "Iter :220000,\t, process: 20181 Loss: 0.1763205547742892\n",
      "Iter :230000,\t, process: 20179 Loss: 0.15238592242721472\n",
      "Iter :240000,\t, process: 20179 Loss: 0.1876637927714467\n",
      "Iter :250000,\t, process: 20177 Loss: 0.16865918144054431\n",
      "Iter :260000,\t, process: 20180 Loss: 0.14608558120139317\n",
      "Iter :270000,\t, process: 20173 Loss: 0.1937125225435235\n",
      "Iter :280000,\t, process: 20178 Loss: 0.19294090031896788\n",
      "Iter :290000,\t, process: 20178 Loss: 0.14549883253217372\n",
      "Iter :300000,\t, process: 20177 Loss: 0.16129666521180896\n",
      "Iter :310000,\t, process: 20180 Loss: 0.17085563216136235\n",
      "Iter :320000,\t, process: 20177 Loss: 0.1847997685697319\n",
      "Iter :330000,\t, process: 20170 Loss: 0.1547186762067718\n",
      "Iter :340000,\t, process: 20181 Loss: 0.1528410304918652\n",
      "Iter :350000,\t, process: 20173 Loss: 0.13205423671659874\n",
      "Iter :360000,\t, process: 20177 Loss: 0.1341389955037019\n",
      "Iter :370000,\t, process: 20179 Loss: 0.14801960418761256\n",
      "Iter :380000,\t, process: 20182 Loss: 0.1752442393698945\n",
      "Iter :390000,\t, process: 20181 Loss: 0.17391859425542883\n",
      "Iter :400000,\t, process: 20173 Loss: 0.1567328543347979\n",
      "Iter :410000,\t, process: 20170 Loss: 0.17136833680966201\n",
      "Iter :420000,\t, process: 20179 Loss: 0.1404788509331063\n",
      "Iter :430000,\t, process: 20181 Loss: 0.12578204812154886\n",
      "Iter :440000,\t, process: 20178 Loss: 0.1463690325966487\n",
      "Iter :450000,\t, process: 20170 Loss: 0.1237900549291426\n",
      "Iter :460000,\t, process: 20182 Loss: 0.12281042103220334\n",
      "Iter :470000,\t, process: 20179 Loss: 0.1645877843385497\n",
      "Iter :480000,\t, process: 20179 Loss: 0.12096033313340171\n",
      "Iter :490000,\t, process: 20181 Loss: 0.1413786256125091\n",
      "Iter :500000,\t, process: 20179 Loss: 0.14051680642097825\n",
      "Iter :510000,\t, process: 20173 Loss: 0.13369682674130487\n",
      "Iter :520000,\t, process: 20179 Loss: 0.11971351133845644\n",
      "Iter :530000,\t, process: 20179 Loss: 0.11071757016061556\n",
      "Iter :540000,\t, process: 20181 Loss: 0.11839539037541685\n",
      "Iter :550000,\t, process: 20177 Loss: 0.13654192609403215\n",
      "Iter :560000,\t, process: 20180 Loss: 0.1299624930455613\n",
      "Iter :570000,\t, process: 20180 Loss: 0.12590479937889146\n",
      "Iter :580000,\t, process: 20178 Loss: 0.11605739889869846\n",
      "Iter :590000,\t, process: 20170 Loss: 0.13384574093860005\n",
      "Iter :600000,\t, process: 20181 Loss: 0.10688443194615543\n",
      "Iter :610000,\t, process: 20178 Loss: 0.10638137918873712\n",
      "Iter :620000,\t, process: 20173 Loss: 0.12255292065981477\n",
      "Iter :630000,\t, process: 20180 Loss: 0.15166009124355756\n",
      "Iter :640000,\t, process: 20170 Loss: 0.1130259069280595\n",
      "Iter :650000,\t, process: 20181 Loss: 0.11174167216997011\n",
      "Iter :660000,\t, process: 20180 Loss: 0.10889876281062094\n",
      "Iter :670000,\t, process: 20178 Loss: 0.1106461671823212\n",
      "Iter :680000,\t, process: 20180 Loss: 0.12870218901873168\n",
      "Iter :690000,\t, process: 20180 Loss: 0.1108821676017635\n",
      "Iter :700000,\t, process: 20170 Loss: 0.102708183423382\n",
      "Iter :710000,\t, process: 20173 Loss: 0.14678923083655634\n",
      "Iter :720000,\t, process: 20178 Loss: 0.12102968011456969\n",
      "Iter :730000,\t, process: 20173 Loss: 0.10577492108057586\n",
      "Iter :740000,\t, process: 20179 Loss: 0.10727936636276592\n",
      "Iter :750000,\t, process: 20182 Loss: 0.12555737376588927\n",
      "Iter :760000,\t, process: 20177 Loss: 0.10823801263187328\n",
      "Iter :770000,\t, process: 20180 Loss: 0.10040223919917733\n",
      "Iter :780000,\t, process: 20180 Loss: 0.1056169612826929\n",
      "Iter :790000,\t, process: 20178 Loss: 0.12037608333504773\n",
      "Iter :800000,\t, process: 20178 Loss: 0.11621589534677096\n",
      "Iter :810000,\t, process: 20170 Loss: 0.10448805766219137\n",
      "Iter :820000,\t, process: 20179 Loss: 0.1172172806162169\n",
      "Iter :830000,\t, process: 20173 Loss: 0.12262961865226989\n",
      "Iter :840000,\t, process: 20181 Loss: 0.11655422509287403\n",
      "Iter :850000,\t, process: 20181 Loss: 0.11788833513620471\n",
      "Iter :860000,\t, process: 20173 Loss: 0.1052296294148652\n",
      "Iter :870000,\t, process: 20177 Loss: 0.09762261247685916\n",
      "Iter :880000,\t, process: 20170 Loss: 0.11528410961502528\n",
      "Iter :890000,\t, process: 20181 Loss: 0.11349363511374824\n",
      "Iter :900000,\t, process: 20181 Loss: 0.11967001217143837\n",
      "Iter :910000,\t, process: 20181 Loss: 0.1186819118413236\n",
      "Iter :920000,\t, process: 20170 Loss: 0.1153729425244471\n",
      "Iter :930000,\t, process: 20178 Loss: 0.11886041156690619\n",
      "Iter :940000,\t, process: 20182 Loss: 0.10324713372712699\n",
      "Iter :950000,\t, process: 20182 Loss: 0.0959685435487024\n",
      "Iter :960000,\t, process: 20177 Loss: 0.09969731513408936\n",
      "Iter :970000,\t, process: 20177 Loss: 0.11273930089367973\n",
      "Iter :980000,\t, process: 20177 Loss: 0.1135102023279153\n",
      "Iter :990000,\t, process: 20178 Loss: 0.11656943310215852\n",
      "Process 20173 is killed\n",
      "Process 20178 is killed\n",
      "Process 20177 is killed\n",
      "Process 20170 is killed\n",
      "Process 20182 is killed\n",
      "Process 20180 is killed\n",
      "Process 20181 is killed\n",
      "Process 20179 is killed\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Multi-core. Took 62.28173368697753 seconds...\n"
     ]
    }
   ],
   "source": [
    "start = default_timer()\n",
    "ls = []\n",
    "for n in range(n_cpu):\n",
    "    proc = mp.Process(target=worker, args=[queue, output_queue])\n",
    "    ls.append(proc)\n",
    "    proc.start()\n",
    "\n",
    "for proc in ls:\n",
    "    proc.join()\n",
    "end = default_timer()\n",
    "print(f'Multi-core. Took {end - start} seconds...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_history = []\n",
    "loss_history = []\n",
    "\n",
    "while not output_queue.empty():\n",
    "    stamp, loss = output_queue.get()\n",
    "    timestep_history.append(stamp)\n",
    "    loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(timestep_history, loss_history)\n",
    "plt.xlabel('training time(seconds)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME0lZHuKAFE-"
   },
   "source": [
    "Hello, I'm `Misha` and here's what i've done:\n",
    "\n",
    "* I created the list of indexes and then put into mp.Queue\n",
    "* After that I just used mp.Pool and mp.Queue, pretty easy task to be honest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlops-new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ad9d993d9b5e2a413384441c723ee3eaf312374b965fcfaa00a4bb1e33d21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
